{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal\n",
    "# to try and pull call for papers from popular sources so that we can store that data\n",
    "# into a database, and then query based on keywords of interest\n",
    "# ideally this will then be automated and availabble\n",
    "\n",
    "# Known sources:\n",
    "# PaperCall: https://www.papercall.io/events\n",
    "# Sessionize: https://www.google.com/search?q=%22call+for+speakers/papers%22+site:sessionize.com+%222021%22+-%22Call+for+Speakers+is+closed%22\n",
    "# thanks to Michael - look for the site map!https://sessionize.com/sitemap/events.xml\n",
    "# Sands media: https://callforpapers.sandsmedia.com/\n",
    "# Eventil: https://eventil.com/\n",
    "# tulu.la: https://tulu.la/events/\n",
    "\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EventURL:\n",
    "    def __init__(self, url, source):\n",
    "        self.url = url\n",
    "        self.source = source\n",
    "\n",
    "class Event:\n",
    "        def __init__(self, title, event_url, submit_url, cfp_closing, start_date, \n",
    "                     end_date, description, location, tags, source):\n",
    "            self.title = title\n",
    "            self.event_url = event_url\n",
    "            self.submit_url = submit_url\n",
    "            self.cfp_closing = cfp_closing\n",
    "            self.start_date = start_date\n",
    "            self.end_date = end_date\n",
    "            self.description = description\n",
    "            self.location = location\n",
    "            self.tags = tags\n",
    "            self.source = source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "class Neo4jConnection:\n",
    "    \n",
    "    def __init__(self, uri, user, pwd):\n",
    "        \n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        \n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "        \n",
    "    def close(self):\n",
    "        \n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "        \n",
    "    def query(self, query, parameters=None, db=None):\n",
    "        \n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        \n",
    "        try: \n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session() \n",
    "            response = list(session.run(query, parameters))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally: \n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "page_no = 0\n",
    "event_list = [];\n",
    "\n",
    "while True:\n",
    "    page_no = page_no + 1\n",
    "    \n",
    "    url = \"https://www.papercall.io/events?page=%s\"%(page_no)\n",
    "    htmlContent = requests.get(url, verify=False)\n",
    "    data = htmlContent.text\n",
    "\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "\n",
    "    #keep iterating through the pages until we've finished\n",
    "\n",
    "    try:\n",
    "        events = soup.find_all(\"div\",class_=\"row event-list-detail\")\n",
    "        if len(events) == 0:\n",
    "            break\n",
    "    except:\n",
    "        print(\"ouch\")\n",
    "        break\n",
    "    \n",
    "    for event in events:\n",
    "\n",
    "        #get CfP closing date - quasi-test to see if event has closed\n",
    "        try:\n",
    "            cfp_closing = datetime.strptime(event.tbody.find(\"time\")[\"datetime\"][0:9], \"%Y-%m-%d\").date()\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        #get event URL\n",
    "        try:\n",
    "            event_url = event.h4.find(\"a\").getText()\n",
    "        except:\n",
    "            try:\n",
    "                event_url = event.h3.find(\"a\")[\"href\"]\n",
    "            except:\n",
    "                event_url = \"unknown\"\n",
    "            \n",
    "        #get event title, dates, description and location, submit url\n",
    "        info = event.find(\"div\", class_=\"col-md-2 event-list-buttons\")\n",
    "\n",
    "        try:\n",
    "            submit_url = info.find(\"a\", class_=\"btn btn--green-l\")[\"href\"]\n",
    "        except:\n",
    "            submit_url = \"unknown\"\n",
    "        \n",
    "        try:\n",
    "            start_date = datetime.strptime(info.find(\"var\", class_=\"atc_date_start\").getText(), \"%B %d, %Y\").date()\n",
    "        except:\n",
    "            start_date = \"unknown\"\n",
    "        \n",
    "        try:\n",
    "            end_date = datetime.strptime(info.find(\"var\", class_=\"atc_date_end\").getText(), \"%B %d, %Y\").date()\n",
    "        except:\n",
    "            end_date = \"unknown\"\n",
    "        \n",
    "        try:\n",
    "            title = info.find(\"var\", class_=\"atc_title\").getText()\n",
    "        except:\n",
    "                try:\n",
    "                    title = event.h3.find(\"a\").getText()\n",
    "                except:\n",
    "                    title = \"unknown\"\n",
    "        \n",
    "        try:\n",
    "            description = info.find(\"var\", class_=\"atc_description\").getText()\n",
    "        except:\n",
    "            description = \"unknown\"\n",
    "        \n",
    "        try:\n",
    "            location = info.find(\"var\", class_=\"atc_location\").getText()\n",
    "        except:\n",
    "            location = \"unknown\"\n",
    "\n",
    "        #get the event tags if they exist\n",
    "        tags = []\n",
    "        try:\n",
    "            tags = event.find(\"div\", class_=\"col-md-11 col-sm-12\").find_all(\"h4\")[3].getText().replace(\"\\n\",\"\").split(\",\")\n",
    "            tags = list(filter(None,tags))\n",
    "        except:\n",
    "            {}\n",
    "\n",
    "        #event_made = Event(title, event_url, submit_url, cfp_closing, start_date, end_date, description, location, tags)\n",
    "        #print(event_made.title)\n",
    "        event_list.append(Event(title, event_url, submit_url, cfp_closing, start_date, end_date, \n",
    "                                description, location, tags, \"PaperCall\"))\n",
    "\n",
    "     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sessionize using sitemap\n",
    "url = \"https://sessionize.com/sitemap/events.xml\"\n",
    "sess_list = []\n",
    "\n",
    "htmlContent = requests.get(url, verify=False)\n",
    "data = htmlContent.text\n",
    "\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "events = soup.find_all(\"url\")\n",
    "\n",
    "for event in events:\n",
    "    if event.find(\"priority\").getText() == \"0.8\":\n",
    "        sess_list.append(event.find(\"loc\").getText())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now get Sessionize data\n",
    "for url in sess_list:    \n",
    "    try:\n",
    "        htmlContent = requests.get(url, verify=False)\n",
    "        data = htmlContent.text\n",
    "        soup = BeautifulSoup(data, 'html.parser')\n",
    "    except:\n",
    "        print(url)\n",
    "        continue\n",
    "    #print(soup)\n",
    "    \n",
    "    #has this event already closed?\n",
    "\n",
    "    if soup.find(\"div\", class_=\"alert alert-danger\") is not None:\n",
    "        continue\n",
    "    \n",
    "    #title, event_url, submit_url, cfp_closing, start_date, end_date, description, location, tags)\n",
    "    try:\n",
    "        title = soup.find(\"div\", class_=\"col-md-6 animated fadeInLeft\").find(\"h4\").getText()\n",
    "    except:\n",
    "        #maybe 404?\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        content = soup.find(\"div\", class_=\"col-md-6 animated fadeInLeft\")\n",
    "    except:\n",
    "        print(\"ouch2\", url)\n",
    "    try:\n",
    "        dates = content.find_all(\"div\", class_=\"col-sm-6 m-b-md\")\n",
    "        start_date = datetime.strptime(dates[0].find(\"h2\").getText(), \"%d %b %Y\").date()\n",
    "    except:\n",
    "        print(\"ouch3\", url)\n",
    "        start_date = datetime.strptime(dates[0].find(\"h2\").getText(), \"%d %b %Y\").date()\n",
    "        print(start_date)\n",
    "    try:\n",
    "        end_date = datetime.strptime(dates[1].find(\"h2\").getText(), \"%d %b %Y\").date()\n",
    "        #print(end_date)\n",
    "    except:\n",
    "        end_date = start_date\n",
    "    try:\n",
    "        event_url = content.find(\"a\").getText()\n",
    "    except:\n",
    "        event_url = \"unknown\"\n",
    "    try:\n",
    "        location = content.find(\"div\", class_=\"col-sm-12 m-b-md\").find(\"h2\").getText()\n",
    "    except:\n",
    "        continue  \n",
    "   \n",
    "    \n",
    "    try:    \n",
    "        desc_items = content.find_all(\"div\", class_=\"col-sm-12\")\n",
    "        description = \"\".join([item.text for item in desc_items])\n",
    "    except:\n",
    "        print(\"ouch5\", url)\n",
    "        \n",
    "    try:\n",
    "        content = soup.find(\"div\", class_=\"col-md-6 animated fadeInRight\")\n",
    "        cfp_closing = datetime.strptime(content.find_all(\"div\", class_=\"col-sm-6 m-b-sm\")[1].find(\"h2\").getText(), \"%d %b %Y\").date()\n",
    "    except:\n",
    "        print(\"ouch 6\", url)\n",
    "        \n",
    "    event_list.append(Event(title, event_url, url, cfp_closing, start_date, end_date, \n",
    "                             description, location, [\"\"], \"Sessionize\"))\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading SO tags\n",
      "loading countries\n"
     ]
    }
   ],
   "source": [
    "#Connect up to the Neo4j instance\n",
    "conn = Neo4jConnection(uri='bolt://54.152.43.56:7687', user='neo4j', pwd='')\n",
    "\n",
    "# database clearout\n",
    "conn.query(\"\"\"MATCH (n) DETACH DELETE n\"\"\")\n",
    "\n",
    "# set the indexes\n",
    "\n",
    "try:\n",
    "    query = \"\"\"\n",
    "        CREATE INDEX ON :Location(value);\n",
    "        CREATE INDEX ON :Tag(value);\n",
    "        CREATE INDEX ON :Synonym(value);\n",
    "    \"\"\"\n",
    "    conn.query(query)\n",
    "except:\n",
    "    #indexes are probably already set\n",
    "    print(sys.exc_info())\n",
    "    \n",
    "    \n",
    "# Load the StackOverflow tags and synonyms\n",
    "# For now, we'll switch out hyphens for spaces\n",
    "try:\n",
    "    print(\"loading SO tags\")\n",
    "    conn.query(\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM 'https://raw.githubusercontent.com/lju-lazarevic/misc/main/sor.csv' AS row\n",
    "        WITH row.Tag AS tag, split(row.synonyms, ';') AS syms\n",
    "        MERGE (t:Tag {value:replace(tag, '-',' ')})\n",
    "            ON CREATE SET t.source = 'StackOverflow'\n",
    "        WITH t, syms\n",
    "        FOREACH (n IN syms | \n",
    "            MERGE (s:Synonym {value:replace(n,'-',' ')})\n",
    "            CREATE (t)-[:HAS_SYNONYM]->(s))\"\"\")\n",
    "except:\n",
    "    print(sys.exc_info())\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get stuff into neo\n",
    "for event in event_list:\n",
    "    try:\n",
    "        #start creating!\n",
    "        tag = list(filter(None, event.tags))\n",
    "        params = {'title':event.title,\n",
    "                  'eventURL':event.event_url,\n",
    "                  'submitURL':event.submit_url, \n",
    "                  'startDate':event.start_date,\n",
    "                  'endDate':event.end_date,\n",
    "                  'description':event.description,\n",
    "                  'source':event.source,\n",
    "                  'cfpClosing':event.cfp_closing,\n",
    "                  'lvalue':event.location.strip(),\n",
    "                  'tags':tag}\n",
    "\n",
    "        query = \"\"\"CREATE (e:Event {title: $title, eventURL: $eventURL, submitURL: $submitURL, startDate: $startDate,\n",
    "                            endDate: $endDate, description: $description, source: $source, cfpClosing: $cfpClosing})\n",
    "                   MERGE (l:Location {value:$lvalue})\n",
    "                   WITH e, l\n",
    "                   CREATE (e)-[:IN_LOCATION]->(l)\n",
    "                   WITH e\n",
    "                   UNWIND $tags as tag\n",
    "                   MERGE (t:Tag {value:tolower(trim(tag))})\n",
    "                   CREATE (e)-[:HAS_TAG {count:1}]->(t)\"\"\"\n",
    "\n",
    "        conn.query(query, parameters=params)\n",
    "\n",
    "    except:\n",
    "        print(event.submit_url)\n",
    "        print(sys.exc_info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can do all of this stuff in python, but just showing what's possible in the db too\n",
    "# do some similarity mapping to tags\n",
    "\n",
    "# start linking tags to events. We'll keep a count in the r.source property \n",
    "# for how often the tag occurs (e.g. to catch 'if')\n",
    "try:\n",
    "    conn.query(\"\"\"\n",
    "        MATCH (e:Event), (t:Tag)\n",
    "        WITH e, t, tolower(\" \"+e.title+\" \" + e.description) AS text, \n",
    "            apoc.text.format(\"(\\\\b%s\\\\b|\\\\B %s\\\\b)\", [replace(t.value, '.','\\.'), replace(t.value, '.','\\.')]) AS rp\n",
    "        WITH e, t, size(apoc.text.regexGroups(text, rp)) as c \n",
    "            WHERE c>0 AND NOT (e)-[:HAS_TAG]->(t)\n",
    "        MERGE (e)-[r:PREDICTED_TAG]->(t)\n",
    "            ON CREATE SET r.count = c, r.source = 'tag'\n",
    "            ON MATCH SET r.count = r.count+c\"\"\")\n",
    "except:\n",
    "    print(\"shrug predict tag\")\n",
    "    \n",
    "# now use the synonyms to try and find any more. We'll keep a count in the r.source property \n",
    "# for how often the tag occurs (e.g. to catch 'if')\n",
    "try:\n",
    "    conn.query(\"\"\"\n",
    "        MATCH (e:Event), (t:Tag)--(s:Synonym)\n",
    "        WITH e, t, tolower(\" \"+e.title+\" \" + e.description) AS text, \n",
    "            apoc.text.format(\"(\\\\b%s\\\\b|\\\\B %s\\\\b)\", [replace(s.value, '.','\\.'), replace(s.value, '.','\\.')]) AS rp\n",
    "        WITH e, t, size(apoc.text.regexGroups(text, rp)) as c \n",
    "            WHERE c>0 AND NOT (e)-[:HAS_TAG]->(t)\n",
    "        MERGE (e)-[r:PREDICTED_TAG]->(t)\n",
    "            ON CREATE SET r.count = c, r.source = 'synonymn'\n",
    "            ON MATCH SET r.count = r.count+c\"\"\")\n",
    "except:\n",
    "        print(sys.exc_info())\n",
    "\n",
    "#check to see whether there are similar tags from SO and from PC and reduce\n",
    "\n",
    "#do some basic stats to clean up predicted tags\n",
    "\n",
    "#Do we have a crazy ratio between a count of a predicted tag and how often it occurs?\n",
    "try:\n",
    "    conn.query(\"\"\"\n",
    "        MATCH (e:Event)-[r:PREDICTED_TAG]->(t:Tag)\n",
    "        WITH r, t, tofloat(sum(r.count))/tofloat(count(e)) AS ratio WHERE ratio >10 \n",
    "        WITH r, t\n",
    "        DELETE r\"\"\")\n",
    "except:\n",
    "        print(sys.exc_info())\n",
    "        \n",
    "#Does a predicted tag appear in over 20% of the talks? \n",
    "try:\n",
    "    conn.query(\"\"\"\n",
    "        MATCH (e:Event)\n",
    "        WITH count(e) AS events\n",
    "        MATCH (e:Event)-[r:PREDICTED_TAG]->(t:Tag)\n",
    "        WITH t, count(e) AS occ, events\n",
    "        WITH t, occ, tofloat(occ)/tofloat(events) AS ratio WHERE ratio >0.2\n",
    "        MATCH (e:Event)-[r:PREDICTED_TAG]->(t:Tag)\n",
    "        DELETE r\"\"\")\n",
    "except:\n",
    "        print(sys.exc_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eyeballing the data, do some simple clean-up of tags:\n",
    "match (e:Event)-[r]->(t:Tag)\n",
    "WITH r, t, tofloat(sum(r.count))/tofloat(count(e)) as ratio WHERE ratio >10 \n",
    "DELETE r\n",
    "\n",
    "#where occurence/freq ration is greater than 20%, let's cut (if predicted!)\n",
    "MATCH (e:Event)\n",
    "WITH count(e) AS events\n",
    "MATCH (e:Event)-[r:PREDICTED_TAG]->(t:Tag)\n",
    "WITH t, count(e) AS occ, events\n",
    "WITH t, occ, tofloat(occ)/tofloat(events) AS ratio WHERE ratio >0.2\n",
    "MATCH (e:Event)-[r:PREDICTED_TAG]->(t:Tag)\n",
    "DELETE r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Queries for the data\n",
    "\n",
    "CALL gds.graph.create.cypher(\"similar\", \n",
    "\"MATCH (e:Event) RETURN id(e) AS id\",\n",
    "\"MATCH (e1:Event)-->(t:Tag)<--(e2:Event) RETURN id(e1) AS source, id(e2) AS target\")\n",
    "\n",
    "call gds.nodeSimilarity.stream(\"similar\")\n",
    "YIELD node1, node2, similarity\n",
    "RETURN gds.util.asNode(node1).title, gds.util.asNode(node2).title, similarity order by similarity desc\n",
    "\n",
    "call gds.nodeSimilarity.stream(\"similar\")\n",
    "YIELD node1, node2, similarity\n",
    "WITH gds.util.asNode(node1) as n1, gds.util.asNode(node2) as n2, similarity WHERE similarity >= 0.8\n",
    "CREATE (n1)-[:SIMILAR_TO]->(n2)\n",
    "\n",
    "call gds.nodeSimilarity.stream(\"similar\")\n",
    "YIELD node1, node2, similarity\n",
    "WITH gds.util.asNode(node1) as n1, gds.util.asNode(node2) as n2, similarity WHERE similarity >= 0.8 AND id(n1)>id(n2)\n",
    "CREATE (n1)-[:SIMILAR_TO]->(n2)\n",
    "\n",
    "#similar events\n",
    "match (e:Event)-[:SIMILAR_TO]->(e2)\n",
    "WHERE NOT  ()-->(e)\n",
    "WITH e\n",
    "MATCH (e)-[:SIMILAR_TO*]->(e1)\n",
    "return distinct  e.title, collect(distinct e1.title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
